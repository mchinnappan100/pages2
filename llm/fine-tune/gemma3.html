<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fine-Tuning Gemma 3 Models</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  <link rel="icon" type="image/x-icon" href="https://mohan-chinnappan-n5.github.io/dfv/img/mc_favIcon.ico">
  <!-- Prism.js CSS for syntax highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
  <style>
    body {
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }
    main {
      flex: 1;
    }
    html {
      scroll-behavior: smooth;
    }
    img {
      border: 5px solid #ccc;
      border-radius: 8px;
      box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.3);
      margin: 10px;
      max-width: 100%;
      height: auto;
      display: block;
    }
    /* Style for copy button */
    .copy-btn {
      position: absolute;
      top: 0.5rem;
      right: 0.5rem;
      transition: background-color 0.2s;
    }
    .copy-btn:hover {
      background-color: #2563eb;
    }
    pre {
      position: relative;
      background-color: #f4f4f4;
      padding: 2rem 1rem 1rem;
      border-radius: 0.5rem;
    }
  </style>
</head>
<body class="bg-gray-100 font-sans">
  <!-- Sticky Navbar -->
  <nav class="bg-blue-600 text-white shadow-lg sticky top-0 z-50">
    <div class="max-w-6xl mx-auto px-4 py-4 flex justify-between items-center">
      <div class="text-2xl font-bold">
        <a href="#home">Fine-Tuning Gemma 3</a>
      </div>
      <div class="space-x-4">
        <a href="#home" class="hover:text-blue-200">Home</a>
        <a href="#features" class="hover:text-blue-200">Features</a>
        <a href="#techniques" class="hover:text-blue-200">Techniques</a>
        <a href="https://github.com/mchinnappan100/gemma3-finetuning" class="bg-blue-500 px-4 py-2 rounded hover:bg-blue-400">View on GitHub</a>
      </div>
    </div>
  </nav>

  <!-- Main Content -->
  <main>
    <!-- Hero Section -->
    <section id="home" class="bg-gradient-to-r from-blue-500 to-blue-700 text-white py-20">
      <div class="max-w-6xl mx-auto px-4 text-center">
        <h1 class="text-5xl font-bold mb-4">Fine-Tuning Gemma 3 Models</h1>
        <p class="text-xl mb-8">Learn how to fine-tune Google's Gemma 3 models efficiently using techniques like LoRA, quantization, and supervised fine-tuning for downstream tasks.</p>
        <a href="#techniques" class="bg-white text-blue-600 px-6 py-3 rounded-lg font-semibold hover:bg-gray-200">Explore Techniques</a>
      </div>
    </section>

    <!-- Features Section -->
    <section id="features" class="py-16">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-gray-800 text-center mb-12">Features of Gemma 3 Fine-Tuning</h2>
        <div class="grid grid-cols-1 md:grid-cols-4 gap-8">
          <!-- Feature 1 -->
          <div class="bg-white p-6 rounded-lg shadow-md text-center">
            <div class="text-blue-600 text-4xl mb-4">‚ö°</div>
            <h3 class="text-xl font-semibold mb-2">Memory Efficiency</h3>
            <p class="text-gray-600">Techniques like LoRA and 4-bit quantization reduce memory usage, enabling fine-tuning on consumer GPUs.</p>
          </div>
          <!-- Feature 2 -->
          <div class="bg-white p-6 rounded-lg shadow-md text-center">
            <div class="text-blue-600 text-4xl mb-4">üöÄ</div>
            <h3 class="text-xl font-semibold mb-2">Fast Training</h3>
            <p class="text-gray-600">Optimized methods like mixed precision and gradient checkpointing speed up training without sacrificing quality.</p>
          </div>
          <!-- Feature 3 -->
          <div class="bg-white p-6 rounded-lg shadow-md text-center">
            <div class="text-blue-600 text-4xl mb-4">üì¶</div>
            <h3 class="text-xl font-semibold mb-2">Small Model Weights</h3>
            <p class="text-gray-600">LoRA produces compact model weights (a few hundred MBs), ideal for deployment.</p>
          </div>
          <!-- Feature 4 -->
          <div class="bg-white p-6 rounded-lg shadow-md text-center">
            <div class="text-blue-600 text-4xl mb-4">‚úÖ</div>
            <h3 class="text-xl font-semibold mb-2">High-Quality Outputs</h3>
            <p class="text-gray-600">Maintains Gemma 3's performance on downstream tasks with minimal parameter updates.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Fine-Tuning Techniques Section -->
    <section id="techniques" class="py-16">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-gray-800 mb-8">Fine-Tuning Techniques for Gemma 3</h2>
        <p class="text-gray-600 mb-6">Explore the key techniques used to fine-tune Gemma 3 models efficiently:</p>
        <div class="space-y-6">
          <!-- Technique 1: LoRA -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">üîπ Low Rank Adaptation (LoRA)</h3>
            <p class="text-gray-600 mb-4">Low Rank Adaptation (LoRA) is a fine-tuning technique that greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. This technique makes training with LoRA much faster and more memory-efficient, and produces smaller model weights (a few hundred MBs), all while maintaining the quality of the model outputs.</p>
            <p class="text-gray-600 mb-4">Example LoRA configuration for Gemma 3:</p>
            <pre>
              <code class="language-python">
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)
model = get_peft_model(model, lora_config)
              </code>
              <button class="copy-btn bg-blue-600 text-white px-2 py-1 rounded text-sm" onclick="copyCode(this)">Copy</button>
            </pre>
          </div>
          <!-- Technique 2: 4-bit Quantization -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">üîπ 4-bit Quantization</h3>
            <p class="text-gray-600 mb-4">4-bit quantization, implemented via the <code>bitsandbytes</code> library, reduces the model‚Äôs memory footprint by representing weights in 4-bit precision. This allows Gemma 3 to be fine-tuned on GPUs with limited memory, such as the T4 in Google Colab.</p>
            <p class="text-gray-600 mb-4">Example quantization setup:</p>
            <pre>
              <code class="language-python">
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "google/gemma-3-4b-it",
    device_map="auto",
    torch_dtype=torch.bfloat16,
    load_in_4bit=True,
    quantization_config={"bnb_4bit_compute_dtype": torch.bfloat16}
)
              </code>
              <button class="copy-btn bg-blue-600 text-white px-2 py-1 rounded text-sm" onclick="copyCode(this)">Copy</button>
            </pre>
          </div>
          <!-- Technique 3: Supervised Fine-Tuning (SFT) -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">üîπ Supervised Fine-Tuning (SFT)</h3>
            <p class="text-gray-600 mb-4">Supervised Fine-Tuning (SFT) involves training Gemma 3 on a task-specific dataset to adapt it to particular applications, such as question answering or text generation. The <code>trl</code> library‚Äôs <code>SFTTrainer</code> simplifies this process.</p>
            <p class="text-gray-600 mb-4">Example SFT setup:</p>
            <pre>
              <code class="language-python">
from trl import SFTTrainer
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./gemma3_finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_steps=100,
    save_total_limit=2,
    optim="adamw_torch"
)

trainer = SFTTrainer(
    model=model,
    train_dataset=tokenized_dataset,
    args=training_args
)
trainer.train()
              </code>
              <button class="copy-btn bg-blue-600 text-white px-2 py-1 rounded text-sm" onclick="copyCode(this)">Copy</button>
            </pre>
          </div>
          <!-- Technique 4: Gradient Checkpointing -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">üîπ Gradient Checkpointing</h3>
            <p class="text-gray-600 mb-4">Gradient checkpointing reduces memory usage by recomputing intermediate activations during the backward pass, making it possible to fine-tune large models like Gemma 3 on limited hardware.</p>
            <p class="text-gray-600 mb-4">Example setup:</p>
            <pre>
              <code class="language-python">
model.gradient_checkpointing_enable()
training_args = TrainingArguments(
    ...,
    gradient_checkpointing=True
)
              </code>
              <button class="copy-btn bg-blue-600 text-white px-2 py-1 rounded text-sm" onclick="copyCode(this)">Copy</button>
            </pre>
          </div>
          <!-- Technique 5: Mixed Precision Training -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">üîπ Mixed Precision Training</h3>
            <p class="text-gray-600 mb-4">Mixed precision training uses 16-bit floating-point (FP16 or BF16) computations to speed up training and reduce memory usage while maintaining model accuracy.</p>
            <p class="text-gray-600 mb-4">Example setup:</p>
            <pre>
              <code class="language-python">
training_args = TrainingArguments(
    ...,
    fp16=True  # Enable mixed precision
)
              </code>
              <button class="copy-btn bg-blue-600 text-white px-2 py-1 rounded text-sm" onclick="copyCode(this)">Copy</button>
            </pre>
          </div>
        </div>
        <div class="mt-8">
          <h3 class="text-xl font-semibold text-gray-800 mb-4">Prerequisites</h3>
          <p class="text-gray-600">Ensure the following are installed and configured:</p>
          <ul class="list-disc list-inside text-gray-600">
            <li>Python 3.8+ with libraries: <code>torch</code>, <code>transformers</code>, <code>datasets</code>, <code>peft</code>, <code>trl</code>, <code>accelerate</code>, <code>bitsandbytes</code>.</li>
            <li>A GPU (e.g., NVIDIA T4 in Google Colab) for efficient training.</li>
            <li>Access to the <code>google/gemma-3-4b-it</code> model on Hugging Face (requires authentication).</li>
            <li>A task-specific dataset, such as <code>TheFinAI/Fino1_Reasoning_Path_FinQA</code>.</li>
          </ul>
        </div>
      </div>
    </section>
  </main>

  <!-- Footer -->
  <footer class="bg-blue-600 text-white py-6">
    <div class="max-w-6xl mx-auto px-4 text-center">
      <p>Made with ‚ù§Ô∏è in <a href="https://en.wikipedia.org/wiki/New_Hampshire" class="text-blue-200 hover:underline">New Hampshire</a> by <a href="https://mohan-chinnappan-n.github.io/about/cv.html" class="text-blue-200 hover:underline">mc</a></p>
    </div>
  </footer>

  <!-- Prism.js for syntax highlighting -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <!-- Clipboard copy script -->
  <script>
    function copyCode(button) {
      const code = button.previousElementSibling.textContent;
      navigator.clipboard.writeText(code.trim()).then(() => {
        button.textContent = 'Copied!';
        button.classList.add('bg-green-600');
        setTimeout(() => {
          button.textContent = 'Copy';
          button.classList.remove('bg-green-600');
        }, 2000);
      }).catch(err => {
        console.error('Failed to copy:', err);
        button.textContent = 'Error';
        button.classList.add('bg-red-600');
        setTimeout(() => {
          button.textContent = 'Copy';
          button.classList.remove('bg-red-600');
        }, 2000);
      });
    }
  </script>
</body>
</html>