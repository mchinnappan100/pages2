<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LLM Query Node Setup Guide</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  <link rel="icon" type="image/x-icon" href="https://mohan-chinnappan-n5.github.io/dfv/img/mc_favIcon.ico">
  <!-- Prism.js CSS -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
  <style>
    body {
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }
    main {
      flex: 1;
    }
    html {
      scroll-behavior: smooth;
    }
    /* Style for the copy button */
    .copy-btn {
      transition: background-color 0.3s;
    }
    .copy-btn:hover {
      background-color: #2563eb !important;
    }
    /* Adjust Prism.js code block styling */
    pre[class*="language-"] {
      position: relative;
      background: #f5f2f0 !important;
      border-radius: 0.5rem;
      padding: 1rem;
      overflow-x: auto;
      font-size: 0.875rem;
    }
    code[class*="language-"] {
      background: none !important;
    }
  </style>
</head>
<body class="bg-gray-100 font-sans">
  <!-- Sticky Navbar -->
  <nav class="bg-blue-600 text-white shadow-lg sticky top-0 z-50">
    <div class="max-w-6xl mx-auto px-4 py-4 flex justify-between items-center">
      <div class="text-2xl font-bold">
        <a href="#home">LLM Query Node</a>
      </div>
      <div class="space-x-4">
        <a href="#home" class="hover:text-blue-200">Home</a>
        <a href="#overview" class="hover:text-blue-200">Overview</a>
        <a href="#setup" class="hover:text-blue-200">Setup Steps</a>
      </div>
    </div>
  </nav>

  <!-- Main Content -->
  <main>
    <!-- Hero Section -->
    <section id="home" class="bg-gradient-to-r from-blue-500 to-blue-700 text-white py-20">
      <div class="max-w-6xl mx-auto px-4 text-center">
        <h1 class="text-5xl font-bold mb-4">LLM Query Node Setup Guide</h1>
        <p class="text-xl mb-8">A step-by-step guide to installing and testing the LLM Query Node in Node-RED for querying a local LLM like Ollama.</p>
        <a href="#setup" class="bg-white text-blue-600 px-6 py-3 rounded-lg font-semibold hover:bg-gray-200">Get Started</a>
      </div>
    </section>

    <!-- Overview Section -->
    <section id="overview" class="py-16">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-gray-800 text-center mb-12">Overview</h2>
        <div class="bg-white p-6 rounded-lg shadow-md">
          <p class="text-gray-600">The <strong>LLM Query Node</strong> is a custom Node-RED node that allows you to query a local Language Model (LLM) such as Ollama. This guide will walk you through installing Node-RED (if not already installed), setting up an Ollama server, adding the <code>node-red-contrib-llm-query</code> node, and testing it with a sample flow. Once set up, you can send prompts to your LLM and receive responses directly in your Node-RED flows.</p>
        </div>
      </div>
    </section>

    <!-- Setup Steps Section -->
    <section id="setup" class="py-16">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-gray-800 mb-8">Setup Steps</h2>
        <p class="text-gray-600 mb-6">Follow these steps to set up and test the LLM Query Node in Node-RED:</p>
        <div class="space-y-6">
          <!-- Step 1: Install Node-RED -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 1: Install Node-RED</h3>
            <p class="text-gray-600 mb-4">If you donâ€™t have Node-RED installed, install it using npm (Node.js package manager). First, ensure Node.js is installed:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step1a">node --version</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step1a')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">If Node.js is not installed, download and install it from <a href="https://nodejs.org/" class="text-blue-600 hover:underline">nodejs.org</a>. Then, install Node-RED globally:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step1b">npm install -g node-red</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step1b')">Copy</button>
            </div>
          </div>

          <!-- Step 2: Start Node-RED -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 2: Start Node-RED</h3>
            <p class="text-gray-600 mb-4">Start the Node-RED server:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step2">node-red</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step2')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Open your browser and navigate to <code>http://localhost:1880</code> to access the Node-RED editor. If the port is different, the terminal will show the correct URL.</p>
          </div>

          <!-- Step 3: Set Up Ollama Server -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 3: Set Up Ollama Server</h3>
            <p class="text-gray-600 mb-4">The LLM Query Node uses a local Ollama server for LLM queries. Install Ollama if you havenâ€™t already:</p>
            <p class="text-gray-600 mb-4">Download and install Ollama from <a href="https://ollama.com" class="text-blue-600 hover:underline">ollama.com</a>. Then, start the Ollama server:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step3a">ollama serve</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step3a')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Pull the <code>llama3.2</code> model (or another model of your choice):</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step3b">ollama pull llama3.2</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step3b')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Verify the server is running by listing available models:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step3c">curl http://localhost:11434/api/tags</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step3c')">Copy</button>
            </div>
          </div>

          <!-- Step 4: Install the LLM Query Node -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 4: Install the LLM Query Node</h3>
            <p class="text-gray-600 mb-4">Create a directory for the custom node and set up the project:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step4a">mkdir node-red-contrib-llm-query
cd node-red-contrib-llm-query
npm init -y</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4a')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Update the <code>package.json</code> file with the following content:</p>
            <div class="relative">
              <pre class="language-json"><code id="code-step4b">{
  "name": "node-red-contrib-llm-query",
  "version": "0.0.1",
  "description": "A Node-RED node to query a local LLM with a configurable model",
  "main": "llm-query.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "node-red": {
    "nodes": {
      "llm-query": "llm-query.js"
    }
  },
  "keywords": [
    "node-red",
    "llm",
    "ai",
    "ollama"
  ],
  "author": "Your Name",
  "license": "MIT"
}</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4b')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Create the <code>llm-query.js</code> file with the following content:</p>
            <div class="relative">
              <pre class="language-javascript"><code id="code-step4c">module.exports = function (RED) {
    function LLMQueryNode(config) {
        RED.nodes.createNode(this, config);
        const node = this;
        node.prompt = config.prompt;
        node.url = config.url || "http://localhost:11434/api/generate";
        node.model = config.model;
        node.on('input', async function (msg) {
            const prompt = msg.prompt || node.prompt;
            const model = msg.model || node.model;
            if (!prompt) {
                node.error("No prompt provided.");
                return;
            }
            if (!model) {
                node.error("No model specified.");
                return;
            }
            const payload = { prompt: prompt, model: model, stream: false };
            try {
                const response = await fetch(node.url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) {
                    node.error(`Error in call: ${response.statusText}`);
                    return;
                }
                const result = await response.json();
                msg.payload = result.response || "No response";
                node.send(msg);
            } catch (error) {
                node.error(`Failed to connect to the LLM endpoint: ${error.message}`, error);
            }
        });
    }
    RED.nodes.registerType("llm-query", LLMQueryNode);
}</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4c')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Create the <code>llm-query.html</code> file with the following content:</p>
            <div class="relative">
              <pre class="language-html"><code id="code-step4d">&lt;script type="text/javascript"&gt;
    RED.nodes.registerType('llm-query', {
        category: 'AI',
        color: '#a6bbcf',
        defaults: {
            name: { value: "" },
            prompt: { value: "", required: true },
            url: { value: "http://localhost:11434/api/generate" },
            model: { value: "llama3.2", required: true }
        },
        inputs: 1,
        outputs: 1,
        icon: "font-awesome/fa-question-circle",
        label: function () {
            return this.name || "llm-query";
        }
    });
&lt;/script&gt;

&lt;script type="text/html" data-template-name="llm-query"&gt;
    &lt;div class="form-row"&gt;
        &lt;label for="node-input-name"&gt;&lt;i class="fa fa-tag"&gt;&lt;/i&gt; Name&lt;/label&gt;
        &lt;input type="text" id="node-input-name" placeholder="Name"&gt;
    &lt;/div&gt;
    &lt;div class="form-row"&gt;
        &lt;label for="node-input-prompt"&gt;&lt;i class="fa fa-comment"&gt;&lt;/i&gt; Prompt&lt;/label&gt;
        &lt;input type="text" id="node-input-prompt" placeholder="Enter your prompt"&gt;
    &lt;/div&gt;
    &lt;div class="form-row"&gt;
        &lt;label for="node-input-url"&gt;&lt;i class="fa fa-link"&gt;&lt;/i&gt; URL&lt;/label&gt;
        &lt;input type="text" id="node-input-url" placeholder="http://localhost:11434/api/generate"&gt;
    &lt;/div&gt;
    &lt;div class="form-row"&gt;
        &lt;label for="node-input-model"&gt;&lt;i class="fa fa-cube"&gt;&lt;/i&gt; Model&lt;/label&gt;
        &lt;input type="text" id="node-input-model" placeholder="e.g., llama3.2"&gt;
    &lt;/div&gt;
&lt;/script&gt;

&lt;script type="text/html" data-help-name="llm-query"&gt;
    &lt;p&gt;A node to query a local LLM (e.g., via Ollama) with a prompt and return the response.&lt;/p&gt;
    &lt;h3&gt;Inputs&lt;/h3&gt;
    &lt;dl class="message-properties"&gt;
        &lt;dt&gt;prompt&lt;/dt&gt;
        &lt;dd&gt;The prompt to send to the LLM. Overrides the node's configured prompt if provided.&lt;/dd&gt;
        &lt;dt&gt;model&lt;/dt&gt;
        &lt;dd&gt;The model name to use (e.g., "llama3.2"). Overrides the node's configured model if provided.&lt;/dd&gt;
    &lt;/dl&gt;
    &lt;h3&gt;Outputs&lt;/h3&gt;
    &lt;dl class="message-properties"&gt;
        &lt;dt&gt;payload&lt;/dt&gt;
        &lt;dd&gt;The response from the LLM, or "No response" if none is provided.&lt;/dd&gt;
    &lt;/dl&gt;
    &lt;h3&gt;Details&lt;/h3&gt;
    &lt;p&gt;This node sends a prompt to a local LLM endpoint (default: &lt;code&gt;http://localhost:11434/api/generate&lt;/code&gt;) and returns the response.&lt;/p&gt;
    &lt;p&gt;Configure the prompt, URL, and model in the node's properties, or override them via &lt;code&gt;msg.prompt&lt;/code&gt; and &lt;code&gt;msg.model&lt;/code&gt;.&lt;/p&gt;
&lt;/script&gt;</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4d')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Install the node in Node-REDâ€™s user directory (default: <code>~/.node-red</code>):</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step4e">cd ~/.node-red
npm link /path/to/node-red-contrib-llm-query</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4e')">Copy</button>
            </div>
            <p class="text-gray-600 mt-4">Restart Node-RED to load the new node:</p>
            <div class="relative">
              <pre class="language-bash"><code id="code-step4f">node-red-stop
node-red-start</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step4f')">Copy</button>
            </div>
          </div>

          <!-- Step 5: Create and Test a Flow -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 5: Create and Test a Flow</h3>
            <p class="text-gray-600 mb-4">In the Node-RED editor, create a flow to test the LLM Query Node:</p>
            <ol class="list-decimal list-inside text-gray-600 space-y-2">
              <li>Drag an <code>inject</code> node, an <code>llm-query</code> node (under the "AI" category), and a <code>debug</code> node into the workspace.</li>
              <li>Connect them: <code>inject</code> â†’ <code>llm-query</code> â†’ <code>debug</code>.</li>
              <li>Double-click the <code>inject</code> node and set the payload to a string, e.g., <code>msg.prompt = "Why is the sky blue?"</code>.</li>
              <li>Double-click the <code>llm-query</code> node and configure:
                <ul class="list-disc list-inside ml-4">
                  <li><strong>Prompt</strong>: Leave blank to use <code>msg.prompt</code>.</li>
                  <li><strong>URL</strong>: <code>http://localhost:11434/api/generate</code></li>
                  <li><strong>Model</strong>: <code>llama3.2</code></li>
                </ul>
              </li>
              <li>Double-click the <code>debug</code> node and set it to display <code>msg.payload</code>.</li>
              <li>Click <strong>Deploy</strong> to save the flow.</li>
              <li>Click the button on the <code>inject</code> node to trigger the flow.</li>
            </ol>
            <p class="text-gray-600 mt-4">Check the debug sidebar in the Node-RED editor. You should see the LLMâ€™s response, e.g.:</p>
            <div class="relative">
              <pre class="language-text"><code id="code-step5">The sky is blue due to Rayleigh scattering...</code></pre>
              <button class="copy-btn absolute top-2 right-2 bg-blue-600 text-white px-3 py-1 rounded hover:bg-blue-700" onclick="copyCode('code-step5')">Copy</button>
            </div>
          </div>

          <!-- Step 6: Troubleshooting -->
          <div class="bg-white p-6 rounded-lg shadow-md">
            <h3 class="text-xl font-semibold text-gray-800 mb-2">ðŸ”¹ Step 6: Troubleshooting</h3>
            <p class="text-gray-600 mb-4">If you encounter issues, try the following:</p>
            <ul class="list-disc list-inside text-gray-600 space-y-2">
              <li><strong>Ollama Not Running</strong>: Ensure the Ollama server is running (<code>ollama serve</code>) and the model is pulled (<code>ollama pull llama3.2</code>).</li>
              <li><strong>Connection Error</strong>: Verify the URL in the <code>llm-query</code> node matches your Ollama server (<code>http://localhost:11434/api/generate</code>).</li>
              <li><strong>Node Not Found</strong>: Restart Node-RED after installing the node, and ensure itâ€™s in the <code>~/.node-red/node_modules</code> directory.</li>
              <li><strong>Debug Output</strong>: Check the Node-RED logs in the terminal for detailed error messages, e.g., <code>Failed to connect to the LLM endpoint</code>.</li>
            </ul>
          </div>
        </div>
      </div>
    </section>
  </main>

  <!-- Footer -->
  <footer class="bg-blue-600 text-white py-6">
    <div class="max-w-6xl mx-auto px-4 text-center">
      <p>MC - LLM Query Node Guide</p>
    </div>
  </footer>

  <!-- Prism.js JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>

  <!-- JavaScript for Copy Functionality -->
  <script>
    function copyCode(elementId) {
      const codeElement = document.getElementById(elementId);
      const text = codeElement.innerText;
      navigator.clipboard.writeText(text).then(() => {
        alert('Code copied to clipboard!');
      }).catch(err => {
        console.error('Failed to copy: ', err);
      });
    }
  </script>
</body>
</html>